{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a23aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"./ml/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4aa385",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [\"enrollment-api.pdf\", \"pet-api.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efc767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=path + file_name[0],\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=path,)\n",
    "\n",
    "raw_pdf_elements = raw_pdf_elements + partition_pdf(\n",
    "    filename=path + file_name[1],\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6a345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "tables = []\n",
    "texts = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        tables.append(str(element))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        texts.append(str(element))\n",
    "\n",
    "print(len(tables))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90278980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "from PIL import Image as _PILImage\n",
    "\n",
    "# Create chroma\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"metlife_rag_clip\", embedding_function=OpenCLIPEmbeddings()\n",
    ")\n",
    "\n",
    "# Get image URIs with .jpg extension only\n",
    "image_uris = sorted(\n",
    "    [\n",
    "        os.path.join(path, image_name)\n",
    "        for image_name in os.listdir(path)\n",
    "        if image_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Add images\n",
    "vectorstore.add_images(uris=image_uris)\n",
    "\n",
    "# Add documents\n",
    "vectorstore.add_texts(texts=texts)\n",
    "\n",
    "# Make retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9097341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string.\n",
    "\n",
    "    Args:\n",
    "    base64_string (str): Base64 string of the original image.\n",
    "    size (tuple): Desired size of the image as (width, height).\n",
    "\n",
    "    Returns:\n",
    "    str: Base64 string of the resized image.\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def is_base64(s):\n",
    "    \"\"\"Check if a string is Base64 encoded\"\"\"\n",
    "    try:\n",
    "        return base64.b64encode(base64.b64decode(s)) == s.encode()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"Split numpy array images and texts\"\"\"\n",
    "    images = []\n",
    "    text = []\n",
    "    for doc in docs:\n",
    "        doc = doc.page_content  # Extract Document contents\n",
    "        if is_base64(doc):\n",
    "            # Resize image to avoid OAI server error\n",
    "            images.append(\n",
    "                resize_base64_image(doc, size=(250, 250))\n",
    "            )  # base64 encoded str\n",
    "        else:\n",
    "            text.append(doc)\n",
    "    return {\"images\": images, \"texts\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6387fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough,RunnableParallel\n",
    "\n",
    "\n",
    "def prompt_func(dict):\n",
    "    format_texts = \"\\n\".join(dict[\"context\"][\"texts\"])\n",
    "    messages = []\n",
    "    if dict[\"context\"][\"images\"]:\n",
    "        image_message = {\n",
    "            \"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{dict['context']['images'][0]}\"}\n",
    "        }\n",
    "        messages.append(image_message)\n",
    "    \n",
    "    text_message = {\"type\": \"text\", \"text\": f\"\"\"Answer the question based only on the following context, which can include text, tables, and the below image:\n",
    "                Question: {dict[\"question\"]}\n",
    "                Text and tables:\n",
    "                {format_texts}\n",
    "                \"\"\"}\n",
    "    messages.append(text_message)\n",
    "    \n",
    "    return [\n",
    "        HumanMessage(\n",
    "            content=messages\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a3b5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0,\n",
    "                   openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                   model=\"gpt-4-vision-preview\",\n",
    "                   max_tokens=2048)\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableParallel({\"response\":prompt_func| model| StrOutputParser(),\n",
    "                      \"context\": itemgetter(\"context\"),})\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebbf45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f900822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the list of all Enrollment API URLs are:\n",
      "\n",
      "1. Test Environment URL for LIMRA Enrollment Delivery API:\n",
      "   - https://qa.api.metlife.com/metlife/qa/gvwb/enrollmentServices/api/v1/enrollments\n",
      "\n",
      "2. Production Environment URL for LIMRA Enrollment Delivery API:\n",
      "   - https://api.metlife.com/metlife/production/gvwb/enrollmentServices/api/v1/enrollments\n",
      "\n",
      "3. Test Environment URL for Security/Token API:\n",
      "   - https://qa.api.metlife.com/metlife/qa/authorization/token\n",
      "\n",
      "4. Production Environment URL for Security/Token API:\n",
      "   - https://api.metlife.com/metlife/production/authorization/token\n",
      "\n",
      "(Note: The context provided also includes URLs for the MetLife Pet Insurance API, but since the question specifically asks for Enrollment API URLs, those have not been included in the list.)\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"Give me a list of all Enrollment API URLs\")\n",
    "print(response[\"response\"])\n",
    "for image in response['context']['images']:\n",
    "    plt_img_base64(response['context']['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e605c40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the list of all Pet API URLs are as follows:\n",
      "\n",
      "1. Catalog API:\n",
      "   - Test Environment URL: https://qa.api.metlife.com/metlife/qa/channel/catalogsservices/tpe/v1/tenants/US/views/products/catalogs?q=product.typeCode==1100\n",
      "   - Production Environment URL: https://api.metlife.com/metlife/production/channel/catalogsservices/tpe/v1/tenants/US/views/products/catalogs?q=product.typeCode==1100\n",
      "\n",
      "2. Create Application API:\n",
      "   - Test Environment URL: https://qa.api.metlife.com/metlife/qa/channel/applicationsservices/tpe/v1/tenants/US/products/applications/create\n",
      "   - Production Environment URL: https://api.metlife.com/metlife/production/channel/applicationsservices/tpe/v1/tenants/US/products/applications/create\n",
      "\n",
      "3. Generate Quote API:\n",
      "   - Test Environment URL: https://qa.api.metlife.com/metlife/qa/channel/quoteservices/tpe/v1/tenants/US/products/quotes/generate\n",
      "   - Production Environment URL: https://api.metlife.com/metlife/production/channel/quoteservices/tpe/v1/tenants/US/products/quotes/generate\n",
      "\n",
      "4. Submit Application API:\n",
      "   - Test Environment URL: https://qa.api.metlife.com/metlife/qa/channel/applicationsservices/tpe/v1/tenants/US/products/applications/8fd6e9cf-fbbb-48da-b008-91e009c2d542/submit\n",
      "   - Production Environment URL: https://api.metlife.com/metlife/production/channel/applicationsservices/tpe/v1/tenants/US/products/applications/create\n",
      "\n",
      "5. Save Application API:\n",
      "   - Test Environment URL: https://qa.api.metlife.com/metlife/qa/channel/applicationsservices/tpe/v1/tenants/US/products/applications/8fd6e9cf-fbbb-48da-b008-91e009c2d542/save\n",
      "   - Production Environment URL: https://api.metlife.com/metlife/production/channel/applicationsservices/tpe/v1/tenants/US/products/applications/4b2cbf50-aa28-4ea8-bf36-d03ee63cb0af/save\n",
      "\n",
      "6. Security/Token API:\n",
      "   - Test Environment URL: https://qa.api.metlife.com/metlife/qa/authorization/token\n",
      "   - Production Environment URL: https://api.metlife.com/metlife/production/authorization/token\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"Give me a list of all Pet API URLs\")\n",
    "print(response[\"response\"])\n",
    "for image in response['context']['images']:\n",
    "    plt_img_base64(response['context']['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96fc2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the first step to integrate with Metlife would be to make a call to the security/token API to obtain a temporary token.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"What should be my first step to integrate with Metlife?\")\n",
    "print(response[\"response\"])\n",
    "for image in response['context']['images']:\n",
    "    plt_img_base64(response['context']['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897f5195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get access to MetLife APIs, you need to follow a two-step process:\n",
      "\n",
      "1. Make a call to the security/token API to obtain a temporary token.\n",
      "2. Use the obtained token to make a call to the functional API.\n",
      "\n",
      "For detailed steps on calling the Token API and the Functional API, refer to the API Integration Guide provided by MetLife.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"How do I get access to MetLife APIs\")\n",
    "print(response[\"response\"])\n",
    "for image in response['context']['images']:\n",
    "    plt_img_base64(response['context']['images'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
